{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "# gradcam\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    return [os.path.join(path, label, filename) for label in os.listdir(path) for filename in os.listdir(os.path.join(path, label))]\n",
    "\n",
    "def move_files(files, target_path):\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    for filepath in files:\n",
    "        target_filepath = os.path.join(target_path, filepath.split(\"/\")[-2])\n",
    "        os.makedirs(target_filepath, exist_ok=True)\n",
    "        shutil.copy(filepath, target_filepath)\n",
    "\n",
    "    print(f\"[INFO] Moved {len(files)} files to {target_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset -p ../data\n",
    "!unzip -o ../data/brain-tumor-mri-dataset.zip -d ../data/brain_tumor_mri_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/brain_tumor_mri_dataset/Training\"\n",
    "validtest_path = \"../data/brain_tumor_mri_dataset/Testing\"\n",
    "train_files = list_files(train_path)\n",
    "validtest_files = list_files(validtest_path)\n",
    "len(train_files), len(validtest_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files, test_files = train_test_split(\n",
    "    validtest_files,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=[filename.split(\"/\")[-2] for filename in validtest_files]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/brain_tumor_mri_dataset/train\"\n",
    "move_files(train_files, train_path)\n",
    "\n",
    "valid_path = \"../data/brain_tumor_mri_dataset/validation\"\n",
    "move_files(valid_files, valid_path)\n",
    "\n",
    "test_path = \"../data/brain_tumor_mri_dataset/test\"\n",
    "move_files(test_files, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [os.path.join(root_dir, label, filename) for label in os.listdir(root_dir) for filename in os.listdir(os.path.join(root_dir, label))]\n",
    "        labels = sorted(os.listdir(root_dir))\n",
    "        self.label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        image = Image.open(filename).convert('RGB')\n",
    "        label = self.label2idx[filename.split(\"/\")[-2]]\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image)\n",
    "        return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "preprocess = weights.transforms()\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/brain_tumor_mri_dataset/train\"\n",
    "\n",
    "valid_path = \"../data/brain_tumor_mri_dataset/validation\"\n",
    "\n",
    "test_path = \"../data/brain_tumor_mri_dataset/test\"\n",
    "\n",
    "train_ds = BrainTumorDataset(train_path, transform=preprocess)\n",
    "valid_ds = BrainTumorDataset(valid_path, transform=preprocess)\n",
    "test_ds = BrainTumorDataset(test_path, transform=preprocess)\n",
    "\n",
    "print(f\"Train dataset: {len(train_ds)}\")\n",
    "print(f\"Validation dataset: {len(valid_ds)}\")\n",
    "print(f\"Test dataset: {len(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=32, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = efficientnet_b0(weights=weights)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[1] = nn.Linear(1280, 4)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "timestamp  = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_targets_all = []\n",
    "    train_preds_all = []\n",
    "\n",
    "    # train step\n",
    "    for batch in train_dl:\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)\n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_targets_all.extend(y.cpu().numpy())\n",
    "        train_preds_all.extend(preds.cpu().numpy())\n",
    "\n",
    "    train_loss /= len(train_dl)\n",
    "    train_acc = accuracy_score(train_targets_all, train_preds_all)\n",
    "\n",
    "    # eval step\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        eval_loss = 0\n",
    "        eval_targets_all = []\n",
    "        eval_preds_all = []\n",
    "\n",
    "        for batch in valid_dl:\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = model(x)\n",
    "            preds = torch.argmax(y_pred, dim=-1)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            eval_loss += loss.item()\n",
    "            eval_targets_all.extend(y.cpu().numpy())\n",
    "            eval_preds_all.extend(preds.cpu().numpy())\n",
    "\n",
    "        eval_loss /= len(valid_dl)\n",
    "        valid_acc = accuracy_score(eval_targets_all, eval_preds_all)\n",
    "\n",
    "\n",
    "    print(f\"[INFO] Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.2%} | Validation Loss: {eval_loss:.4f} | Validation Accuracy: {valid_acc:.2%}\")\n",
    "\n",
    "checkpoint_filename = f\"../models/efficientnet_b0_{timestamp}.pth\"\n",
    "torch.save(model.state_dict(), checkpoint_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval step\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    eval_loss = 0\n",
    "    eval_targets_all = []\n",
    "    eval_preds_all = []\n",
    "\n",
    "    for batch in test_dl:\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)\n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        eval_loss += loss.item()\n",
    "        eval_targets_all.extend(y.cpu().numpy())\n",
    "        eval_preds_all.extend(preds.cpu().numpy())\n",
    "\n",
    "    eval_loss /= len(valid_dl)\n",
    "    valid_acc = accuracy_score(eval_targets_all, eval_preds_all)\n",
    "\n",
    "print(f\"[INFO] Test Loss: {eval_loss:.4f} | Test Accuracy: {valid_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_filename):\n",
    "    model = efficientnet_b0()\n",
    "    model.classifier[1] = nn.Linear(1280, 4)\n",
    "    print(f\"[INFO] Loading checkpoint from {checkpoint_filename}...\")\n",
    "    model.load_state_dict(torch.load(checkpoint_filename))\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "model_loaded = load_checkpoint(\"../models/efficientnet_b0_20241116_121021.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# eval step\n",
    "model_loaded.eval()\n",
    "with torch.inference_mode():\n",
    "    eval_loss = 0\n",
    "    eval_targets_all = []\n",
    "    eval_preds_all = []\n",
    "\n",
    "    for batch in test_dl:\n",
    "        x, y = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model_loaded(x)\n",
    "        preds = torch.argmax(y_pred, dim=-1)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        eval_loss += loss.item()\n",
    "        eval_targets_all.extend(y.cpu().numpy())\n",
    "        eval_preds_all.extend(preds.cpu().numpy())\n",
    "\n",
    "    eval_loss /= len(valid_dl)\n",
    "    valid_acc = accuracy_score(eval_targets_all, eval_preds_all)\n",
    "\n",
    "print(f\"[INFO] Test Loss: {eval_loss:.4f} | Test Accuracy: {valid_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {v: k for k, v in train_ds.label2idx.items()}\n",
    "labels = list(idx2label.values())\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image_tensor = preprocess(image)\n",
    "    return image_tensor.to(device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepath = \"../data/brain_tumor_mri_dataset/test/pituitary/Te-pi_0256.jpg\"\n",
    "image_test = Image.open(test_filepath).convert(\"RGB\")\n",
    "target_label = test_filepath.split(\"/\")[-2]\n",
    "\n",
    "image_tensor = preprocess_image(image_test)\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, image_tensor):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        logits = model(image_tensor)\n",
    "        probs = torch.softmax(logits, dim=-1).detach().cpu().squeeze().numpy()\n",
    "        pred_idx = torch.argmax(logits, dim=-1).item()\n",
    "        pred_label = labels[pred_idx]\n",
    "\n",
    "    return pred_label, probs\n",
    "\n",
    "\n",
    "pred_label, probs = make_prediction(model_loaded, image_tensor)\n",
    "print(f\"Predicted label: {pred_label}\")\n",
    "print(f\"Probabilities: {probs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GramCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradcam(model, input_image, input_tensor, pred_label):\n",
    "    image_resized = input_image.resize((224, 224))\n",
    "    image_np = np.array(image_resized).astype(np.float32) / 255.0\n",
    "\n",
    "    target_layers = [model.features[-1][2]]\n",
    "    targets = [ClassifierOutputTarget(labels.index(pred_label))]\n",
    "\n",
    "    with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "        # In this example grayscale_cam has only one image in the batch:\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        visualization = show_cam_on_image(image_np, grayscale_cam, use_rgb=True)\n",
    "        # You can also get the model outputs without having to redo inference\n",
    "        model_outputs = cam.outputs\n",
    "    \n",
    "    gradcam_image = Image.fromarray(visualization)\n",
    "\n",
    "    return image_resized, gradcam_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized, gradcam_image = compute_gradcam(model_loaded, image_test, image_tensor, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gradcam(image, gradcam_image):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(gradcam_image)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"GradCAM\")\n",
    "    plt.show()\n",
    "\n",
    "display_gradcam(image_resized, gradcam_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
